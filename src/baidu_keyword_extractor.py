import requests
import json
import time
import os
import hashlib
from typing import List, Dict, Optional
from pathlib import Path


class BaiduKeywordExtractor:
    def __init__(self, api_key: str, secret_key: str):
        """
        åˆå§‹åŒ–å…³é”®è¯æå–å™¨ï¼ˆçº¯ç™¾åº¦APIç‰ˆæœ¬ï¼‰

        :param api_key: ç™¾åº¦API Key
        :param secret_key: ç™¾åº¦Secret Key
        """
        self.api_key = api_key
        self.secret_key = secret_key
        self.access_token = None
        self.token_expire_time = 0
        self.total_requests = 0
        self.service_available = False

        # APIé…ç½®
        self.auth_url = "https://aip.baidubce.com/oauth/2.0/token"
        self.keyword_url = "https://aip.baidubce.com/rpc/2.0/nlp/v1/txt_keywords_extraction"
        self.timeout = 15

        self._init_service()

    def _init_service(self):
        """åˆå§‹åŒ–æœåŠ¡è¿æ¥"""
        print("\n=== åˆå§‹åŒ–ç™¾åº¦å…³é”®è¯æå–æœåŠ¡ ===")
        self.access_token = self._get_access_token()
        self.service_available = bool(self.access_token)

    def _get_access_token(self) -> Optional[str]:
        """è·å–ç™¾åº¦APIè®¿é—®ä»¤ç‰Œï¼ˆå¸¦ç¼“å­˜ï¼‰"""
        if self.access_token and time.time() < self.token_expire_time:
            return self.access_token

        print("ğŸ”„ æ­£åœ¨è·å–Access Token...")
        try:
            response = requests.post(
                self.auth_url,
                params={
                    "grant_type": "client_credentials",
                    "client_id": self.api_key,
                    "client_secret": self.secret_key
                },
                timeout=self.timeout
            )
            response.raise_for_status()
            data = response.json()

            if "access_token" in data:
                self.access_token = data["access_token"]
                self.token_expire_time = time.time() + data.get("expires_in", 2592000) - 300  # æå‰5åˆ†é’Ÿè¿‡æœŸ
                print(
                    f"âœ… è·å–TokenæˆåŠŸ (æœ‰æ•ˆæœŸè‡³: {time.strftime('%Y-%m-%d %H:%M:%S', time.localtime(self.token_expire_time))}")
                return self.access_token

            print(f"âŒ è·å–Tokenå¤±è´¥: {data.get('error_description', 'æœªçŸ¥é”™è¯¯')}")
        except Exception as e:
            print(f"âŒ è·å–Tokenå¼‚å¸¸: {str(e)}")
        return None

    def _preprocess_text(self, text: str) -> str:
        """æ–‡æœ¬é¢„å¤„ç†"""
        import re
        # ç§»é™¤ç‰¹æ®Šå­—ç¬¦ä½†ä¿ç•™ä¸­æ–‡æ ‡ç‚¹
        text = re.sub(r'[^\u4e00-\u9fa5a-zA-Z0-9ï¼Œã€‚ï¼Ÿï¼ã€ï¼›ï¼šâ€œâ€â€˜â€™ï¼ˆï¼‰ã€ã€‘â€¦\- \n]', '', text)
        # åˆå¹¶ç©ºç™½å­—ç¬¦
        text = re.sub(r'\s+', ' ', text).strip()
        return text[:2000]  # ç™¾åº¦APIé™åˆ¶

    def extract_unique_keywords(self, original_list):
        seen_words = {}
        result_list = []

        for item in original_list:
            word = item["word"]
            if word not in seen_words:
                seen_words[word] = 1
                result_list.append(item)

        return result_list


    def extract_keywords(self, text: str, num: int = 5, retry: int = 0) -> List[Dict]:
        """
        æå–å…³é”®è¯ï¼ˆçº¯ç™¾åº¦APIç‰ˆæœ¬ï¼‰

        :param text: å¾…å¤„ç†æ–‡æœ¬
        :param num: è¿”å›å…³é”®è¯æ•°é‡
        :param retry: å½“å‰é‡è¯•æ¬¡æ•°ï¼ˆå†…éƒ¨ä½¿ç”¨ï¼‰
        :return: [{"word": str, "score": float}]
        :raises: Exception å½“APIè°ƒç”¨å¤±è´¥æ—¶æŠ›å‡º
        """
        if not self.access_token:
            raise ValueError("Access Tokenä¸å¯ç”¨")

        if not text.strip():
            return []

        payload = {
            "text": [self._preprocess_text(text)],
            "top_num": num  # å®˜æ–¹æ–‡æ¡£è¦æ±‚çš„å‚æ•°å
        }

        print(f"\n=== ç™¾åº¦APIè¯·æ±‚ ===")
        print(f"æ–‡æœ¬é•¿åº¦: {len(payload['text'])}")
        print(f"å‚æ•°: {json.dumps(payload, ensure_ascii=False, indent=2)}")

        try:
            start_time = time.time()
            response = requests.post(
                f"{self.keyword_url}?access_token={self.access_token}",
                headers={
                    "Content-Type": "application/json",
                    "Accept": "application/json"
                },
                data=json.dumps(payload, ensure_ascii=False).encode('utf-8'),
                timeout=self.timeout
            )
            self.total_requests += 1

            print(f"â±ï¸ è¯·æ±‚è€—æ—¶: {(time.time() - start_time):.2f}s")
            print(f"çŠ¶æ€ç : {response.status_code}")

            response.raise_for_status()
            result = response.json()

            print("=== åŸå§‹å“åº” ===")

            if "error_code" in result:
                error_msg = f"ç™¾åº¦APIé”™è¯¯: {result['error_msg']} (code: {result['error_code']})"

                # Tokenè¿‡æœŸå¤„ç†
                if result["error_code"] == 110 and retry < 2:
                    print("ğŸ”„ Tokenå·²è¿‡æœŸï¼Œå°è¯•åˆ·æ–°...")
                    self.access_token = self._get_access_token()
                    if self.access_token:
                        return self.extract_keywords(text, num, retry + 1)

                # QPSé™åˆ¶å¤„ç†
                elif result["error_code"] == 18 and retry < 3:
                    wait_time = 2 ** retry
                    print(f"âš ï¸ è§¦å‘é™æµï¼Œç­‰å¾… {wait_time}s åé‡è¯•...")
                    time.sleep(wait_time)
                    return self.extract_keywords(text, num, retry + 1)

                raise ValueError(error_msg)

            # è°ƒç”¨å‡½æ•°æå–å”¯ä¸€çš„è¯æ±‡åˆ—è¡¨
            print("--", type(result))
            # return result.get("items", [])
            return result.get("results", [])

        except requests.exceptions.RequestException as e:
            print(f"âŒ ç½‘ç»œè¯·æ±‚å¼‚å¸¸: {str(e)}")
            if retry < 3:
                print(f"ğŸ”„ ç¬¬ {retry + 1} æ¬¡é‡è¯•...")
                time.sleep(1)
                return self.extract_keywords(text, num, retry + 1)
            raise

    def process_articles(self, input_path: str, output_path: str):
        """
        å¤„ç†æ‰€æœ‰æ–‡ç« 

        :param input_path: è¾“å…¥JSONæ–‡ä»¶è·¯å¾„
        :param output_path: è¾“å‡ºJSONæ–‡ä»¶è·¯å¾„
        """
        print("\n=== å¼€å§‹å¤„ç†æ–‡ç«  ===")

        # éªŒè¯è¾“å…¥æ–‡ä»¶
        if not os.path.exists(input_path):
            raise FileNotFoundError(f"âŒ è¾“å…¥æ–‡ä»¶ä¸å­˜åœ¨: {input_path}")

        # åŠ è½½æ•°æ®
        with open(input_path, "r", encoding="utf-8") as f:
            articles = json.load(f)

        if not isinstance(articles, list):
            raise ValueError("âŒ è¾“å…¥æ–‡ä»¶åº”è¯¥åŒ…å«JSONæ•°ç»„")

        print(f"ğŸ“‚ æ‰¾åˆ° {len(articles)} ç¯‡æ–‡ç« ")
        results = []
        success_count = 0

        # å¤„ç†æ¯ç¯‡æ–‡ç« 
        for idx, article in enumerate(articles, 1):
            try:
                if not all(k in article for k in ["title", "content"]):
                    raise ValueError("æ–‡ç« ç¼ºå°‘titleæˆ–contentå­—æ®µ")

                content = f"{article['title']}\n{article['content']}"
                print(f"\nğŸ” å¤„ç†æ–‡ç«  #{idx}: {article['title'][:30]}...")

                keywords = self.extract_keywords(content)
                # è¿‡æ»¤é‡å¤çš„æ•°æ®
                keywords = self.extract_unique_keywords(keywords)
                print(f"âœ… æå–åˆ° {len(keywords)} ä¸ªå…³é”®è¯: {[kw['word'] for kw in keywords]}")

                results.append({
                    "id": article.get("id", hashlib.md5(content.encode()).hexdigest()),
                    "title": article["title"],
                    "source": article.get("source", ""),
                    "url": article.get("url", ""),
                    "keywords": [kw["word"] for kw in keywords],
                    "scores": [kw["score"] for kw in keywords]
                })
                success_count += 1

                # æ§åˆ¶è¯·æ±‚é¢‘ç‡
                time.sleep(0.5)

            except Exception as e:
                print(f"âŒ å¤„ç†å¤±è´¥: {str(e)}")
                continue

        # ä¿å­˜ç»“æœ
        output_dir = os.path.dirname(output_path)
        if output_dir and not os.path.exists(output_dir):
            os.makedirs(output_dir)

        with open(output_path, "w", encoding="utf-8") as f:
            json.dump(results, f, ensure_ascii=False, indent=2)

        print(f"\n=== å¤„ç†å®Œæˆ ===")
        print(f"âœ… æˆåŠŸå¤„ç†: {success_count}/{len(articles)}")
        print(f"ğŸ’¾ ç»“æœä¿å­˜åˆ°: {output_path}")
        print(f"ğŸ“Š ç™¾åº¦APIè°ƒç”¨æ¬¡æ•°: {self.total_requests}")


if __name__ == "__main__":
    # ä»config.pyå¯¼å…¥é…ç½®
    from config import BAIDU_API

    BAIDU_API_KEY = BAIDU_API.get("api_key")
    BAIDU_SECRET_KEY = BAIDU_API.get("secret_key")
    print("api", BAIDU_API_KEY)
    print("secret_key", BAIDU_SECRET_KEY)

    # ç¤ºä¾‹ç”¨æ³•
    extractor = BaiduKeywordExtractor(
        api_key=BAIDU_API_KEY,
        secret_key=BAIDU_SECRET_KEY
    )

    # # æµ‹è¯•å•æ¡æ–‡æœ¬
    # test_text = "è¿‘è§†é˜²æ§éœ€è¦æ¯å¤©æˆ·å¤–æ´»åŠ¨2å°æ—¶ï¼Œå‡å°‘ç”µå­å±å¹•ä½¿ç”¨æ—¶é—´ã€‚æœ€æ–°ç ”ç©¶è¡¨æ˜ï¼Œè“å…‰ä¼šåŠ é€Ÿè¿‘è§†å‘å±•ã€‚"
    # print("\n=== æµ‹è¯•å…³é”®è¯æå– ===")
    # try:
    #     keywords = extractor.extract_keywords(test_text)
    #     print(f"æå–ç»“æœ: {keywords}")
    # except Exception as e:
    #     print(f"âŒ æå–å¤±è´¥: {str(e)}")

    # å¤„ç†å…¨éƒ¨æ–‡ç« ï¼ˆç¤ºä¾‹è·¯å¾„ï¼‰
    extractor.process_articles(
        input_path="myopia_articles.json",
        output_path="processed_keywords.json"
    )